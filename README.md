# ğŸµ Hand Gesture Controlled Music Player

Control your music player in **real-time** using simple **hand gestures** captured from your webcam.  
This project combines **computer vision** (gesture recognition) with **Python audio playback** for an interactive experience.

---

## âœ¨ Features
- ğŸ¥ **Real-time hand gesture recognition** using [MediaPipe](https://developers.google.com/mediapipe)  
- ğŸ–ï¸ Supported gestures: **Play/Pause, Stop, Next Track, Previous Track, Volume Up/Down**  
- ğŸ¤– Gesture classification with an **SVM model** trained on custom data  
- ğŸ¶ Music playback with **pygame**  
- âš¡ Stable recognition with **debouncing mechanism** to avoid accidental triggers  

---

## ğŸš€ How It Works
1. **Data Collection**: Capture hand landmark data using MediaPipe (`data_collect.py`).  
2. **Training**: Train an SVM classifier with scikit-learn (`train.py`).  
3. **Run Player**: Launch the real-time player (`gesture_player.py`) to control music with gestures.  

---

## ğŸ› ï¸ Tech Stack
- **Python 3.12**
- **OpenCV** â€“ video capture & visualization  
- **MediaPipe** â€“ hand landmark detection  
- **scikit-learn** â€“ SVM model training  
- **pygame** â€“ music playback  
- **NumPy / Pandas / Joblib** â€“ data handling & model persistence  

---

## ğŸ“‚ Project Structure

```

hand-gesture-music-player/
â”œâ”€ data/              # Collected gesture samples (CSV)
â”œâ”€ models/            # Trained gesture classifier (joblib)
â”œâ”€ music/             # Add your .mp3/.wav files here
â”œâ”€ utils/
â”‚  â””â”€ hand\_features.py
â”œâ”€ data\_collect.py    # Collect labeled hand gesture samples
â”œâ”€ train.py           # Train the SVM classifier
â”œâ”€ gesture\_player.py  # Real-time music player controlled by gestures
â”œâ”€ requirements.txt
â””â”€ README.md

````


## âš¡ Quickstart
1. Clone the repo:
   ```bash
   git clone https://github.com/HirushikaPelagewtta/hand-gesture-music-player.git
   cd hand-gesture-music-player
   
2. Create a Python 3.12 environment and install dependencies:

   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate   # (Windows)
   pip install -r requirements.txt
   ```

3. Collect gesture data:

   ```bash
   python data_collect.py
   ```

4. Train the classifier:

   ```bash
   python train.py
   ```

5. Add music files to the `music/` folder.

6. Run the player:

   ```bash
   python gesture_player.py
   ```

---

## ğŸ“¸ Demo

(Add a GIF or screenshot of the system in action here)

---

## ğŸ”® Future Improvements

* Extend to more gestures (mute, shuffle, playlist control)
* Deploy with a lightweight GUI for non-technical users
* Experiment with deep learning models for improved accuracy

---

## ğŸ“œ License

This project is licensed under the MIT License.

```

